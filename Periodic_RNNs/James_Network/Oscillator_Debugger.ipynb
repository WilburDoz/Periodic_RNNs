{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d804d0c6-f43a-460c-8d2e-a63adae28d71",
   "metadata": {},
   "source": [
    "# Simple repeat networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7221b562-80e3-425b-9ab8-f648aaea3f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import parameters_will\n",
    "import torch.optim as optim\n",
    "import RNN_Will as _model_\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import utils\n",
    "import copy\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "params = parameters_will.default_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b7dd9945-fe3d-4427-a1eb-fca06d9ebe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create the new type of data. There is a freq choice that determines the initialisation, and a desired output\n",
    "freqs = np.array([2, 5])\n",
    "trial_len = params.data.min_length + np.random.randint(params.data.max_length - params.data.min_length)\n",
    "\n",
    "outputs = np.zeros([trial_len, len(freqs)])\n",
    "for (freq_counter, freq) in enumerate(freqs):\n",
    "    outputs[freq-1::freq, freq_counter] = 1\n",
    "\n",
    "input_dict = parameters_will.DotDict()\n",
    "input_dict.freq = torch.from_numpy(freqs)\n",
    "input_dict.outputs = torch.from_numpy(outputs)\n",
    "\n",
    "params.model.num_freqs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0702a419-267d-41fd-b640-d142519e4b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'freq': tensor([2, 3]),\n",
       " 'outputs': tensor([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 0.]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.generate_osc_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "99f559d5-7ce8-4075-ac11-c0d1062093fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h_size': 20,\n",
       " 'hidden_act': 'relu',\n",
       " 'hidden_init_learn': True,\n",
       " 'hidden_init_std': 1,\n",
       " 'transition_init': 'orthogonal',\n",
       " 'output_act': 'sigmoid',\n",
       " 'i_size': 1,\n",
       " 't_size': 1,\n",
       " 'linear_std': 1,\n",
       " 'batch_size': 5,\n",
       " 'num_inits': 2,\n",
       " 'num_freqs': 2,\n",
       " '__class__': parameters_will.DotDict}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "84edd4e4-a4a0-46de-a3bf-c156a6f645d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Oscillator(_model_.VanillaRNN):\n",
    "    def __init__(self, par):\n",
    "        super().__init__(par)\n",
    "        self.hidden_init = nn.Parameter(torch.zeros((self.par.num_freqs, self.par.h_size), dtype=torch.float32), requires_grad=self.par.hidden_init_learn)\n",
    "        \n",
    "    def forward_old(self, inputs, device='cpu'):\n",
    "        T = inputs.outputs.size()[1]\n",
    "        hs, preds, preactivations = torch.zeros([self.par.num_freqs, T, self.par.h_size]), torch.zeros([self.par.num_freqs, T]), torch.zeros([self.par.num_freqs, T, self.par.h_size])\n",
    "        preactivations[:,0,:] = self.hidden_init\n",
    "        hs[:,0,:] = self.activation(preactivations[:,0,:])\n",
    "        preds[:,0:1] = self.out_activation(self.predict(hs[:,0,:]))\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            preactivations[:,t,:] = self.transition(hs[:,t-1,:])\n",
    "            hs[:,t,:] = self.activation(preactivations[:,t,:])\n",
    "            preds[:,t:t+1] = self.out_activation(self.predict(hs[:,0,:]))\n",
    "        \n",
    "        variable_dict = parameters_will.DotDict(\n",
    "            {'hidden': hs,\n",
    "             'pred': preds,\n",
    "             'preactivations':preactivations\n",
    "             })\n",
    "        \n",
    "        return variable_dict\n",
    "        \n",
    "    def forward(self, inputs, device='cpu'):\n",
    "            T = inputs.outputs.size()[0]\n",
    "            pre = self.hidden_init\n",
    "            h  = self.activation(pre)\n",
    "            pred = self.out_activation(self.predict(h))\n",
    "            hs, preds, pres = [], [], []\n",
    "\n",
    "\n",
    "            for t in range(T):\n",
    "                pre = self.transition(h)\n",
    "                h = self.activation(pre)\n",
    "                pred = self.out_activation(self.predict(h))\n",
    "\n",
    "                pres.append(pre)\n",
    "                hs.append(h)\n",
    "                preds.append(pred)\n",
    "\n",
    "            variable_dict = parameters_will.DotDict(\n",
    "                {'hidden': hs,\n",
    "                 'pred': preds,\n",
    "                 'preactivations':preactivations\n",
    "                 })\n",
    "\n",
    "            return variable_dict\n",
    "        \n",
    "model = Oscillator(params.model)\n",
    "variables = model.forward(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9bada1ee-ee36-459d-9b5d-fbec3e7f722f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([204, 2, 1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(variables.pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "888bb513-b3f1-4a93-be0e-602941745d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([204, 2, 1])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict.outputs[:,:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "df32df21-798b-4e9f-9c30-3a04bd1d1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses_osc(model_in, model_out, model, par, device='cpu'):\n",
    "    loss_fit = torch.sum(torch.pow(input_dict.outputs[:,:,None] - torch.stack(variables.pred), 2))\n",
    "    loss_act = torch.sum(torch.pow((torch.stack(variables.hidden)), 2))\n",
    "    return (loss_fit + par.act_weight*loss_act, loss_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "77437f38-ee3b-43d5-b487-36a092aac04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.pow((variables.hidden), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "44088460-ad41-4bae-8be4-187312fd119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 266])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict.outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f48919c-7c0c-47e2-9081-46f3d75de5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 266])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "757ad92f-cbee-4942-90f7-fa4631e392d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DotDict' object has no attribute 'act_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Inverse_Models/Periodic_RNNs/James_Network/parameters_will.py:77\u001b[0m, in \u001b[0;36mDotDict.__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Maintain consistent syntactical behaviour.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'act_weight'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [167]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_losses_osc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [166]\u001b[0m, in \u001b[0;36mcompute_losses_osc\u001b[0;34m(model_in, model_out, model, par, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m loss_fit \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mpow(input_dict\u001b[38;5;241m.\u001b[39moutputs[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(variables\u001b[38;5;241m.\u001b[39mpred), \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      3\u001b[0m loss_act \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mpow((torch\u001b[38;5;241m.\u001b[39mstack(variables\u001b[38;5;241m.\u001b[39mhidden)), \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (loss_fit \u001b[38;5;241m+\u001b[39m \u001b[43mpar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_weight\u001b[49m\u001b[38;5;241m*\u001b[39mloss_act, loss_fit)\n",
      "File \u001b[0;32m~/Documents/Inverse_Models/Periodic_RNNs/James_Network/parameters_will.py:80\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;66;03m# Maintain consistent syntactical behaviour.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDotDict\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         )\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, v):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, DotDict\u001b[38;5;241m.\u001b[39m__convert(v))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;21m__setattr__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;21m__setitem__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DotDict' object has no attribute 'act_weight'"
     ]
    }
   ],
   "source": [
    "compute_losses_osc(input_dict, variables, model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65dc150-b60e-460d-ae77-e1260099b0a4",
   "metadata": {},
   "source": [
    "# Now debugging stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b9069b7e-91f0-48bf-8789-73ff78269043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booting up parameters\n",
      "Making model\n",
      "Starting Training\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "print('Booting up parameters')\n",
    "# Set up our parameters\n",
    "params = parameters_will.default_params()\n",
    "\n",
    "print_iters = 100\n",
    "save_iters = 10000\n",
    "\n",
    "# make instance of model\n",
    "print('Making model')\n",
    "if params.data.oscillators:\n",
    "    model = _model_.Oscillator(params.model)\n",
    "else:\n",
    "    model = _model_.VanillaRNN(params.model)\n",
    "# put model to gpu (if available)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Make an ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=params.train.learning_rate, weight_decay=params.train.weight_decay)\n",
    "min_loss = np.infty\n",
    "\n",
    "if params.data.oscillators:\n",
    "    generator = utils.generate_osc_data\n",
    "else:\n",
    "    generator = utils.generate_data\n",
    "loss_func = _model_.compute_losses_torch\n",
    "\n",
    "print('Starting Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "98cda9ba-bf92-4d2d-a586-af3da96aff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 3.1030e-01,  2.4609e-01, -3.4927e-01, -4.1020e-02,  1.2722e-01,\n",
       "                        2.0545e-01, -2.2556e-01, -2.8088e-01,  1.3100e-01, -1.4480e-01,\n",
       "                       -9.6985e-02, -2.0294e-01,  1.4690e-01, -5.2792e-02,  4.1907e-01,\n",
       "                        2.8068e-01, -2.7462e-01, -1.0354e-01,  1.6196e-01, -2.2684e-01],\n",
       "                      [ 1.3890e-01, -4.5774e-01, -2.6264e-01,  1.3764e-02, -2.5479e-01,\n",
       "                       -5.7501e-02,  5.3634e-01,  1.1849e-01,  6.4628e-02,  5.2944e-02,\n",
       "                       -5.5103e-04, -1.9896e-01,  2.5179e-01, -5.9136e-02,  3.1987e-01,\n",
       "                        1.0078e-01,  2.0040e-01,  1.1037e-01, -1.8953e-01, -1.3378e-01],\n",
       "                      [ 5.5905e-01, -1.4606e-02, -4.6917e-03,  1.6568e-01,  2.0129e-01,\n",
       "                        3.5144e-01, -9.1793e-02,  1.6667e-01,  1.4420e-01,  2.3949e-01,\n",
       "                        3.2777e-01, -9.5097e-02,  1.8704e-01, -2.4320e-01, -3.3018e-01,\n",
       "                       -1.1022e-01,  1.7563e-01, -4.6856e-02, -6.5644e-02,  1.1082e-01],\n",
       "                      [-8.2953e-02,  2.3699e-02,  2.4886e-01, -1.4855e-01, -2.0610e-01,\n",
       "                        5.7822e-02,  2.8812e-01,  6.0634e-02,  9.2437e-02,  3.2948e-01,\n",
       "                        8.8365e-02, -2.1295e-01, -1.2389e-01, -2.4984e-01, -2.5921e-01,\n",
       "                        4.0087e-01, -4.2738e-01, -3.3710e-03,  3.1555e-01, -1.3376e-01],\n",
       "                      [-2.6764e-01, -1.3960e-01,  2.1309e-02,  1.5605e-01,  2.0269e-01,\n",
       "                       -2.5785e-01, -1.0348e-01, -3.0538e-01, -4.3688e-02,  7.4580e-03,\n",
       "                       -2.8813e-01, -3.6741e-01,  3.2360e-01, -3.9482e-01, -2.3549e-01,\n",
       "                        6.5596e-02,  1.0070e-01, -3.1478e-01, -1.2662e-01,  8.3393e-02],\n",
       "                      [-1.4721e-01, -1.6357e-02, -1.1222e-01,  2.5619e-03, -1.9392e-01,\n",
       "                        5.5112e-01,  6.2460e-02,  1.2303e-01, -1.8728e-01, -2.3100e-02,\n",
       "                       -3.8418e-01,  2.6523e-02,  2.7164e-01, -2.7329e-02, -5.7337e-02,\n",
       "                       -2.2792e-01, -4.0019e-01,  7.5001e-02, -1.2476e-01,  3.3177e-01],\n",
       "                      [ 1.2299e-01,  1.9884e-01, -1.6168e-01,  2.4139e-01,  2.1608e-01,\n",
       "                       -2.8950e-01,  3.0031e-02,  2.7229e-01, -4.2966e-01,  6.5169e-02,\n",
       "                       -8.7646e-02, -7.0329e-03, -1.5425e-01, -3.7214e-01,  1.6637e-01,\n",
       "                        1.6256e-01, -6.2794e-02,  4.1177e-01,  5.3811e-02,  2.5694e-01],\n",
       "                      [ 1.5861e-01,  1.1048e-01, -2.5080e-02, -7.7234e-02, -3.8303e-01,\n",
       "                       -2.0144e-01, -2.6860e-01,  2.5356e-01, -2.7385e-01, -2.1655e-01,\n",
       "                       -3.1361e-02,  1.0197e-01,  4.7453e-01,  1.3235e-01, -3.3518e-01,\n",
       "                        2.8540e-01,  7.2986e-02,  5.8254e-02,  3.9804e-02, -2.2857e-01],\n",
       "                      [-1.8590e-01, -1.8774e-01,  3.8471e-01,  2.4001e-01,  1.3118e-01,\n",
       "                        5.8722e-02, -9.6549e-02,  4.6721e-02,  6.3324e-02, -1.9047e-01,\n",
       "                        3.8043e-01, -8.7117e-02,  3.5694e-01,  1.9916e-01,  2.8374e-01,\n",
       "                        2.6760e-01, -9.5005e-02,  1.1101e-01,  1.6200e-01,  3.6474e-01],\n",
       "                      [ 1.2458e-01,  9.7810e-02,  5.4183e-01,  1.6743e-01, -3.2820e-01,\n",
       "                        8.2361e-02, -2.5112e-01,  1.3534e-03, -6.7149e-02,  1.1879e-02,\n",
       "                       -7.5335e-02, -2.5840e-01, -1.5679e-01, -1.7244e-01,  2.7729e-01,\n",
       "                       -8.4255e-02, -7.4570e-03,  9.5918e-02, -4.4196e-01, -2.3612e-01],\n",
       "                      [ 1.9580e-01, -3.0978e-01,  9.7378e-02, -3.5754e-01, -1.6730e-01,\n",
       "                       -2.1025e-01, -3.7918e-01, -5.7954e-02,  2.5161e-01,  2.4856e-01,\n",
       "                       -2.6149e-01,  3.2186e-02,  7.7706e-02, -1.2333e-01,  1.3828e-01,\n",
       "                       -1.8695e-01,  4.5092e-02,  2.5758e-01,  3.3078e-01,  2.4785e-01],\n",
       "                      [-2.4447e-01,  2.3864e-01, -6.6451e-03, -3.5728e-01,  6.5784e-02,\n",
       "                       -2.2511e-02,  4.7798e-02,  3.4644e-01,  6.8878e-02, -3.1509e-01,\n",
       "                        2.5151e-01, -2.9070e-01,  1.5933e-01, -3.1971e-01,  1.1253e-01,\n",
       "                       -4.2742e-01,  4.1389e-02,  2.1813e-02,  1.7255e-01, -1.4749e-01],\n",
       "                      [ 5.4360e-02, -3.0360e-02,  2.1776e-01, -9.9072e-02,  1.0949e-01,\n",
       "                       -4.9230e-02,  9.7392e-02,  1.2350e-01,  7.4017e-02, -2.1082e-02,\n",
       "                       -3.8517e-02,  6.8689e-01,  1.8784e-01, -4.1195e-01,  2.3764e-01,\n",
       "                        8.8292e-02, -1.1593e-01, -3.4314e-01, -1.2076e-01, -7.4188e-02],\n",
       "                      [ 1.9832e-01,  6.9549e-02, -8.2881e-03,  5.1573e-01, -4.0581e-01,\n",
       "                       -1.5163e-01,  1.5961e-01, -4.5189e-02,  2.2302e-01, -3.7083e-01,\n",
       "                       -6.7404e-02,  3.7347e-02, -1.2306e-01, -1.3013e-01, -5.4175e-02,\n",
       "                       -2.1948e-01, -5.2792e-02, -2.0219e-01,  3.6207e-01,  1.5312e-01],\n",
       "                      [-2.0151e-01,  1.8981e-01, -2.2516e-01, -1.3515e-01, -2.5729e-01,\n",
       "                        1.0064e-01, -1.7177e-01,  2.2667e-01,  3.8476e-01, -7.9247e-02,\n",
       "                        6.7912e-03, -2.8888e-02, -2.1589e-01, -1.4243e-01,  1.1432e-02,\n",
       "                        4.1022e-01,  2.6791e-01, -1.0650e-01, -2.5724e-01,  3.9672e-01],\n",
       "                      [-4.4436e-02, -3.0081e-02,  1.9468e-01,  1.1989e-01,  3.0920e-01,\n",
       "                        2.1753e-01,  1.0950e-01,  1.1366e-01,  3.5949e-01, -2.9325e-01,\n",
       "                       -4.4233e-01,  6.9981e-02, -6.3981e-03, -3.6704e-02, -1.7482e-01,\n",
       "                        1.6218e-01,  2.0448e-01,  4.2618e-01,  9.3194e-02, -2.6618e-01],\n",
       "                      [ 1.4666e-01,  2.0489e-01, -1.1501e-02, -1.4379e-02,  1.2928e-01,\n",
       "                       -4.3884e-01,  1.1296e-01,  8.6008e-02,  4.3586e-01,  1.3214e-02,\n",
       "                       -1.7199e-02, -6.2168e-02,  1.6314e-01,  2.1527e-01, -1.2168e-01,\n",
       "                       -1.1043e-01, -4.6087e-01,  1.3786e-01, -4.1372e-01,  9.9401e-02],\n",
       "                      [-9.9587e-02, -5.1171e-01, -2.5546e-01,  4.8611e-02, -2.3689e-02,\n",
       "                        1.2375e-02, -2.9572e-01, -7.4698e-02,  2.8243e-02, -3.1080e-01,\n",
       "                        2.9887e-01,  1.0614e-01, -2.2297e-01, -2.6218e-01, -1.8707e-01,\n",
       "                        3.4316e-03, -3.3818e-01,  2.1140e-01, -1.7124e-01, -1.6445e-01],\n",
       "                      [ 3.1158e-01,  6.0442e-02,  2.0360e-01, -4.2812e-01, -1.3178e-02,\n",
       "                        2.5956e-02,  2.9122e-01, -4.4489e-01, -1.8630e-01, -4.2324e-01,\n",
       "                        7.0876e-02, -1.8296e-02, -5.7079e-02, -1.0373e-01, -1.3398e-01,\n",
       "                        9.3405e-02,  6.7657e-02,  1.3223e-01, -1.2489e-01,  3.0560e-01],\n",
       "                      [-2.6432e-01,  3.3129e-01, -1.1496e-01,  1.5685e-01, -2.2505e-01,\n",
       "                        4.2560e-02,  4.9421e-02, -4.5904e-01,  1.3488e-01,  2.3443e-01,\n",
       "                        2.4015e-01,  2.5376e-01,  2.7773e-01, -1.9643e-01, -6.8623e-03,\n",
       "                       -7.9129e-02,  1.3180e-01,  4.1966e-01, -2.2512e-02, -7.5577e-02]])),\n",
       "             ('bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transition.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_rep_theo",
   "language": "python",
   "name": "neural_rep_theo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
